{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7241e19",
   "metadata": {},
   "source": [
    "#### HABUMUGISHA Emmanuel\n",
    "###### 225229109"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5378492a",
   "metadata": {},
   "source": [
    "### PDL Lab16: Design of LSTM and GRU RNN for classification of IMDB reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d01f77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07cb3464",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd    # to load dataset\n",
    "import numpy as np     # for mathematic equation\n",
    "from nltk.corpus import stopwords   # to get collection of stopwords\n",
    "from sklearn.model_selection import train_test_split       # for splitting dataset\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer  # to encode text to int\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences   # to do padding or truncating\n",
    "from tensorflow.keras.models import Sequential     # the model\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense # layers of the architecture\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint   # save model\n",
    "from tensorflow.keras.models import load_model   # load saved model\n",
    "import re\n",
    "from tensorflow.keras.layers import Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d54ae69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  review sentiment\n",
      "0      One of the other reviewers has mentioned that ...  positive\n",
      "1      A wonderful little production. <br /><br />The...  positive\n",
      "2      I thought this was a wonderful way to spend ti...  positive\n",
      "3      Basically there's a family where a little boy ...  negative\n",
      "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
      "...                                                  ...       ...\n",
      "49995  I thought this movie did a down right good job...  positive\n",
      "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
      "49997  I am a Catholic taught in parochial elementary...  negative\n",
      "49998  I'm going to have to disagree with the previou...  negative\n",
      "49999  No one expects the Star Trek movies to be high...  negative\n",
      "\n",
      "[50000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('IMDB Dataset.csv')\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f8f9911",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95c70be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stops = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14fe2b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews\n",
      "0        [one, reviewers, mentioned, watching, oz, epis...\n",
      "1        [a, wonderful, little, production, the, filmin...\n",
      "2        [i, thought, wonderful, way, spend, time, hot,...\n",
      "3        [basically, family, little, boy, jake, thinks,...\n",
      "4        [petter, mattei, love, time, money, visually, ...\n",
      "                               ...                        \n",
      "49995    [i, thought, movie, right, good, job, it, crea...\n",
      "49996    [bad, plot, bad, dialogue, bad, acting, idioti...\n",
      "49997    [i, catholic, taught, parochial, elementary, s...\n",
      "49998    [i, going, disagree, previous, comment, side, ...\n",
      "49999    [no, one, expects, star, trek, movies, high, a...\n",
      "Name: review, Length: 50000, dtype: object \n",
      "\n",
      "Sentiment\n",
      "0        1\n",
      "1        1\n",
      "2        1\n",
      "3        0\n",
      "4        1\n",
      "        ..\n",
      "49995    1\n",
      "49996    0\n",
      "49997    0\n",
      "49998    0\n",
      "49999    0\n",
      "Name: sentiment, Length: 50000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def load_dataset():\n",
    "    df = pd.read_csv('IMDB Dataset.csv')\n",
    "    x_data = df['review']       # Reviews/Input\n",
    "    y_data = df['sentiment']    # Sentiment/Output\n",
    "\n",
    "    # PRE-PROCESS REVIEW\n",
    "    x_data = x_data.replace({'<.*?>': ''}, regex = True)          # remove html tag\n",
    "    x_data = x_data.replace({'[^A-Za-z]': ' '}, regex = True)     # remove non alphabet\n",
    "    x_data = x_data.apply(lambda review: [w for w in review.split() if w not in english_stops])  # remove stop words\n",
    "    x_data = x_data.apply(lambda review: [w.lower() for w in review])   # lower case\n",
    "    \n",
    "    # ENCODE SENTIMENT -> 0 & 1\n",
    "    y_data = y_data.replace('positive', 1)\n",
    "    y_data = y_data.replace('negative', 0)\n",
    "\n",
    "    return x_data, y_data\n",
    "\n",
    "x_data, y_data = load_dataset()\n",
    "\n",
    "print('Reviews')\n",
    "print(x_data, '\\n')\n",
    "print('Sentiment')\n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f970a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04961ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set\n",
      "7484     [far, sprightly, less, stage, set, bound, gene...\n",
      "11986    [a, strange, relationship, middle, aged, woman...\n",
      "48721    [says, andy, nobody, gets, hurt, everybody, wi...\n",
      "27173    [years, ago, i, caught, fairly, well, made, tv...\n",
      "38456    [when, i, started, watching, i, instantly, not...\n",
      "                               ...                        \n",
      "4290     [i, found, little, gem, extra, feature, dvd, v...\n",
      "13124    [a, year, old, kid, fed, parents, arguing, dec...\n",
      "27777    [although, never, say, never, again, nsna, wea...\n",
      "11601    [yes, i, watch, show, because, girlfriend, wat...\n",
      "2468     [unbelievably, close, real, life, feelings, em...\n",
      "Name: review, Length: 40000, dtype: object \n",
      "\n",
      "4871     [a, antique, shop, owner, nyc, played, joanne,...\n",
      "4030     [watching, film, action, rather, waste, time, ...\n",
      "22854    [a, wonderful, movie, anyone, growing, italian...\n",
      "4805     [i, happened, den, morning, scene, ed, engaged...\n",
      "13926    [this, interesting, project, could, quite, bri...\n",
      "                               ...                        \n",
      "9686     [this, deceptively, laid, back, low, key, casu...\n",
      "20971    [this, film, totally, unbelievable, the, way, ...\n",
      "31694    [this, incredible, comeback, movie, director, ...\n",
      "37877    [blank, check, movie, i, saw, tv, one, day, li...\n",
      "16296    [robin, williams, shows, stand, talents, boost...\n",
      "Name: review, Length: 10000, dtype: object \n",
      "\n",
      "Test Set\n",
      "7484     1\n",
      "11986    1\n",
      "48721    1\n",
      "27173    0\n",
      "38456    0\n",
      "        ..\n",
      "4290     1\n",
      "13124    0\n",
      "27777    1\n",
      "11601    1\n",
      "2468     1\n",
      "Name: sentiment, Length: 40000, dtype: int64 \n",
      "\n",
      "4871     0\n",
      "4030     0\n",
      "22854    1\n",
      "4805     1\n",
      "13926    1\n",
      "        ..\n",
      "9686     1\n",
      "20971    0\n",
      "31694    1\n",
      "37877    0\n",
      "16296    1\n",
      "Name: sentiment, Length: 10000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size = 0.2)\n",
    "\n",
    "print('Train Set')\n",
    "print(x_train, '\\n')\n",
    "print(x_test, '\\n')\n",
    "print('Test Set')\n",
    "print(y_train, '\\n')\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48425887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_length():\n",
    "    review_length = []\n",
    "    for review in x_train:\n",
    "        review_length.append(len(review))\n",
    "\n",
    "    return int(np.ceil(np.mean(review_length)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "281f096d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded X Train\n",
      " [[  131 18203   247 ...     4  1416   151]\n",
      " [   39   585   543 ...   993     8  3505]\n",
      " [  452  2012  1132 ...   415  1716  1518]\n",
      " ...\n",
      " [  164    42    57 ...     0     0     0]\n",
      " [  320     1    33 ...  1118     1    31]\n",
      " [ 3809   402    64 ...     0     0     0]] \n",
      "\n",
      "Encoded X Test\n",
      " [[   39 16916  1814 ...     0     0     0]\n",
      " [   65     4   114 ...     0     0     0]\n",
      " [   39   297     3 ...     0     0     0]\n",
      " ...\n",
      " [    8   975  6949 ...  2677   113    14]\n",
      " [ 3837   722     3 ...     0     0     0]\n",
      " [ 1820  1694   183 ...     0     0     0]] \n",
      "\n",
      "Maximum review length:  130\n"
     ]
    }
   ],
   "source": [
    "# ENCODE REVIEW\n",
    "token = Tokenizer(lower=False)    # no need lower, because already lowered the data in load_data()\n",
    "token.fit_on_texts(x_train)\n",
    "x_train = token.texts_to_sequences(x_train)\n",
    "x_test = token.texts_to_sequences(x_test)\n",
    "\n",
    "max_length = get_max_length()\n",
    "\n",
    "x_train = pad_sequences(x_train, maxlen=max_length, padding='post', truncating='post')\n",
    "x_test = pad_sequences(x_test, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "total_words = len(token.word_index) + 1   # add 1 because of 0 padding\n",
    "\n",
    "print('Encoded X Train\\n', x_train, '\\n')\n",
    "print('Encoded X Test\\n', x_test, '\\n')\n",
    "print('Maximum review length: ', max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee51f705",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fca9614d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 130, 32)           2963616   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                24832     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2992673 (11.42 MB)\n",
      "Trainable params: 2992673 (11.42 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# ARCHITECTURE\n",
    "EMBED_DIM = 32\n",
    "LSTM_OUT = 64\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words, EMBED_DIM, input_length = max_length))\n",
    "model.add(LSTM(LSTM_OUT))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f44b0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "313/313 [==============================] - 55s 162ms/step - loss: 0.4724 - accuracy: 0.7343\n",
      "Epoch 2/10\n",
      "313/313 [==============================] - 55s 177ms/step - loss: 0.2092 - accuracy: 0.9230\n",
      "Epoch 3/10\n",
      "313/313 [==============================] - 63s 201ms/step - loss: 0.1190 - accuracy: 0.9613\n",
      "Epoch 4/10\n",
      "313/313 [==============================] - 64s 204ms/step - loss: 0.0729 - accuracy: 0.9778\n",
      "Epoch 5/10\n",
      "313/313 [==============================] - 52s 167ms/step - loss: 0.0524 - accuracy: 0.9835\n",
      "Epoch 6/10\n",
      "313/313 [==============================] - 54s 172ms/step - loss: 0.0459 - accuracy: 0.9863\n",
      "Epoch 7/10\n",
      "313/313 [==============================] - 53s 169ms/step - loss: 0.0350 - accuracy: 0.9903\n",
      "Epoch 8/10\n",
      "313/313 [==============================] - 50s 161ms/step - loss: 0.0322 - accuracy: 0.9910\n",
      "Epoch 9/10\n",
      "313/313 [==============================] - 50s 161ms/step - loss: 0.0251 - accuracy: 0.9936\n",
      "Epoch 10/10\n",
      "313/313 [==============================] - 50s 160ms/step - loss: 0.0282 - accuracy: 0.9924\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1f318c39af0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size = 128, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7aaff90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 6s 17ms/step - loss: 0.5403 - accuracy: 0.8612\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5403304696083069, 0.8611999750137329]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51f15d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30764504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 130, 32)           2963616   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 32)                8320      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2978273 (11.36 MB)\n",
      "Trainable params: 2978273 (11.36 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# ARCHITECTURE\n",
    "EMBED_DIM = 32\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(Embedding(total_words, EMBED_DIM, input_length = max_length))\n",
    "model1.add(LSTM(32))\n",
    "model1.add(Dense(64, activation='relu'))\n",
    "model1.add(Dense(64, activation='relu'))\n",
    "model1.add(Dense(1, activation='sigmoid'))\n",
    "model1.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e31b4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "313/313 [==============================] - 33s 99ms/step - loss: 0.5009 - accuracy: 0.7097\n",
      "Epoch 2/5\n",
      "313/313 [==============================] - 35s 113ms/step - loss: 0.2116 - accuracy: 0.9205\n",
      "Epoch 3/5\n",
      "313/313 [==============================] - 33s 106ms/step - loss: 0.1128 - accuracy: 0.9615\n",
      "Epoch 4/5\n",
      "313/313 [==============================] - 34s 110ms/step - loss: 0.0675 - accuracy: 0.9790\n",
      "Epoch 5/5\n",
      "313/313 [==============================] - 33s 105ms/step - loss: 0.0467 - accuracy: 0.9848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1f318931c40>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(x_train, y_train, batch_size = 128, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e8ad33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f12741d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 130, 32)           2963616   \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 128)               49664     \n",
      " al)                                                             \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3021601 (11.53 MB)\n",
      "Trainable params: 3021601 (11.53 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# ARCHITECTURE\n",
    "EMBED_DIM = 32\n",
    "LSTM_OUT = 64\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Embedding(total_words, EMBED_DIM, input_length = max_length))\n",
    "model2.add(Bidirectional(LSTM(LSTM_OUT)))\n",
    "model2.add(Dense(64, activation='relu'))\n",
    "model2.add(Dense(1, activation='sigmoid'))\n",
    "model2.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73502016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 81s 248ms/step - loss: 0.3820 - accuracy: 0.8164\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1f32f00b250>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x_train, y_train, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7b8b21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
